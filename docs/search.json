[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bansari’s website",
    "section": "",
    "text": "Welcome to my website!\nI’m a Graduate student pursuing Business Analytics :)"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Bansari’s resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nBansari Kathrotia\n\n\nApr 16, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "Homework 1",
    "section": "",
    "text": "some\nword\nin\nbullets\n\n\nsome\nnumbers\nin\na\nlist\n\ntext can be bold, or italics, or strikethrough\nMy website is https://rsm-bkathrotia.github.io/bkathrotia.github.io/ or here"
  },
  {
    "objectID": "projects/project1/index.html#sub-header",
    "href": "projects/project1/index.html#sub-header",
    "title": "My main Project",
    "section": "",
    "text": "I also analyze data."
  },
  {
    "objectID": "projects/project1/index.html#sub-section",
    "href": "projects/project1/index.html#sub-section",
    "title": "Homework 1",
    "section": "",
    "text": "some\nword\nin\nbullets\n\n\nsome\nnumbers\nin\na\nlist\n\ntext can be bold, or italics, or strikethrough\nMy website is https://rsm-bkathrotia.github.io/bkathrotia.github.io/ or here"
  },
  {
    "objectID": "projects/Assignment1/hw1_questions.html",
    "href": "projects/Assignment1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results.\n\nimport pandas as pd\nimport numpy as np"
  },
  {
    "objectID": "projects/Assignment1/hw1_questions.html#introduction",
    "href": "projects/Assignment1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results.\n\nimport pandas as pd\nimport numpy as np"
  },
  {
    "objectID": "projects/Assignment1/hw1_questions.html#dataset",
    "href": "projects/Assignment1/hw1_questions.html#dataset",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Dataset",
    "text": "Dataset\n\ndata = pd.read_stata('karlan_list_2007.dta')\n#convert the stata file to csv\ndata.to_csv('karlan_list_2007.csv')\ndata\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.000000\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.000000\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.000000\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.000000\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50078\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.872797\n0.089959\n0.257265\n2.13\n45047.0\n0.771316\n0.263744\n1.000000\n\n\n50079\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.688262\n0.108889\n0.288792\n2.67\n74655.0\n0.741931\n0.586466\n1.000000\n\n\n50080\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\n0.900000\n0.021311\n0.178689\n2.36\n26667.0\n0.778689\n0.107930\n0.000000\n\n\n50081\n1\n0\n3\n0\n1\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.917206\n0.008257\n0.225619\n2.57\n39530.0\n0.733988\n0.184768\n0.634903\n\n\n50082\n1\n0\n3\n0\n1\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.530023\n0.074112\n0.340698\n3.70\n48744.0\n0.717843\n0.127941\n0.994181\n\n\n\n\n50083 rows × 51 columns\n\n\n\n\nDescription\nThe dataset contains 50,083 rows and 51 columns with different datatypes.\ntodo: Read the data into R/Python and describe the data\nKey points summarizing the dataset:\n\nExperimental Design: Tracks the impact of different fundraising treatments versus control scenarios on donor behavior.\nMatching and Donation Thresholds: Includes variables for various matching ratios and financial thresholds, influencing donation amounts.\nDonor Demographics and History: Details about donors such as gender, couple status, previous donations, and years since the first donation.\nGeographic and Socioeconomic Factors: Analyzes the influence of state and local demographics, including political alignment and socioeconomic status, on donation patterns.\n\n\n# Printing the results\nprint(f\"Treatment Percentage: {treatment_perc}\")\nprint(f\"Control Percentage: {control_perc}\")\n\nTreatment Percentage: 0.6668130902701516\nControl Percentage: 0.33318690972984844\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n\nT-Test\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper).\nComparing the average values of variables such as mrm2 between treatment and control groups helps us determine if there are any statistically significant differences between these groups at a 95% confidence level.\n\n# Outputting the results of the t-tests\ntreatment_vs_control_stats, control_vs_control_stats\n\n(TtestResult(statistic=0.1194921058159193, pvalue=0.9048859731777738, df=50080.0),\n TtestResult(statistic=0.0, pvalue=1.0, df=33372.0))\n\n\n\n# Print the summary of the model for the Treatment Group\nprint(lin_reg_treatment.summary())\n\n# Visualizing the importance of variables \nprint(lin_reg_treatment.params.sort_values(key=abs, ascending=False))  \n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                dormant   R-squared:                       0.002\nModel:                            OLS   Adj. R-squared:                  0.001\nMethod:                 Least Squares   F-statistic:                     5.652\nDate:                Wed, 17 Apr 2024   Prob (F-statistic):           1.67e-08\nTime:                        22:48:18   Log-Likelihood:                -22664.\nNo. Observations:               31307   AIC:                         4.535e+04\nDf Residuals:                   31296   BIC:                         4.544e+04\nDf Model:                          10                                         \nCovariance Type:            nonrobust                                         \n===================================================================================\n                      coef    std err          t      P&gt;|t|      [0.025      0.975]\n-----------------------------------------------------------------------------------\nIntercept           0.5521      0.053     10.411      0.000       0.448       0.656\nfemale              0.0007      0.006      0.105      0.916      -0.012       0.013\ncouple             -0.0512      0.010     -5.141      0.000      -0.071      -0.032\npwhite             -0.0293      0.041     -0.711      0.477      -0.110       0.051\npblack              0.0494      0.040      1.225      0.221      -0.030       0.129\npage18_39           0.0807      0.046      1.762      0.078      -0.009       0.170\nave_hh_sz          -0.0016      0.013     -0.118      0.906      -0.028       0.025\nmedian_hhincome  5.529e-07   2.85e-07      1.939      0.052   -5.93e-09    1.11e-06\npowner             -0.0190      0.033     -0.572      0.568      -0.084       0.046\npsch_atlstba       -0.0446      0.033     -1.362      0.173      -0.109       0.020\npop_propurban      -0.0323      0.013     -2.503      0.012      -0.058      -0.007\n==============================================================================\nOmnibus:                   107892.795   Durbin-Watson:                   2.001\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5180.478\nSkew:                          -0.088   Prob(JB):                         0.00\nKurtosis:                       1.015   Cond. No.                     1.55e+06\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 1.55e+06. This might indicate that there are\nstrong multicollinearity or other numerical problems.\nIntercept          5.521342e-01\npage18_39          8.066676e-02\ncouple            -5.119242e-02\npblack             4.944180e-02\npsch_atlstba      -4.455806e-02\npop_propurban     -3.227529e-02\npwhite            -2.929282e-02\npowner            -1.903279e-02\nave_hh_sz         -1.570735e-03\nfemale             6.760573e-04\nmedian_hhincome    5.529393e-07\ndtype: float64\n\n\n\n# Print the summary of the model for the Control Group\nprint(lin_reg_control.summary())\n\n# Visualizing the importance of variables (similar simplified method)\nprint(lin_reg_control.params.sort_values(key=abs, ascending=False))\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                dormant   R-squared:                       0.002\nModel:                            OLS   Adj. R-squared:                  0.001\nMethod:                 Least Squares   F-statistic:                     2.579\nDate:                Wed, 17 Apr 2024   Prob (F-statistic):            0.00405\nTime:                        22:48:19   Log-Likelihood:                -11328.\nNo. Observations:               15645   AIC:                         2.268e+04\nDf Residuals:                   15634   BIC:                         2.276e+04\nDf Model:                          10                                         \nCovariance Type:            nonrobust                                         \n===================================================================================\n                      coef    std err          t      P&gt;|t|      [0.025      0.975]\n-----------------------------------------------------------------------------------\nIntercept           0.4533      0.075      6.073      0.000       0.307       0.600\nfemale             -0.0078      0.009     -0.862      0.389      -0.026       0.010\ncouple             -0.0387      0.014     -2.743      0.006      -0.066      -0.011\npwhite              0.1597      0.057      2.780      0.005       0.047       0.272\npblack              0.1424      0.056      2.546      0.011       0.033       0.252\npage18_39          -0.0007      0.065     -0.011      0.991      -0.128       0.127\nave_hh_sz           0.0120      0.019      0.637      0.524      -0.025       0.049\nmedian_hhincome  5.832e-07   4.07e-07      1.432      0.152   -2.15e-07    1.38e-06\npowner             -0.1334      0.047     -2.857      0.004      -0.225      -0.042\npsch_atlstba       -0.0696      0.047     -1.493      0.135      -0.161       0.022\npop_propurban      -0.0159      0.018     -0.882      0.378      -0.051       0.019\n==============================================================================\nOmnibus:                    54058.622   Durbin-Watson:                   2.013\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             2590.424\nSkew:                          -0.085   Prob(JB):                         0.00\nKurtosis:                       1.014   Cond. No.                     1.54e+06\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 1.54e+06. This might indicate that there are\nstrong multicollinearity or other numerical problems.\nIntercept          4.533437e-01\npwhite             1.597181e-01\npblack             1.424140e-01\npowner            -1.333556e-01\npsch_atlstba      -6.961300e-02\ncouple            -3.865036e-02\npop_propurban     -1.593688e-02\nave_hh_sz          1.201257e-02\nfemale            -7.803247e-03\npage18_39         -7.272653e-04\nmedian_hhincome    5.831812e-07\ndtype: float64"
  },
  {
    "objectID": "projects/Assignment1/hw1_questions.html#experimental-results",
    "href": "projects/Assignment1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n\n\n\n\n\n\n\n\n(3.101361000543946,\n 0.0019274025949016982,\n &lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                             OLS Regression Results                            \n ==============================================================================\n Dep. Variable:                   gave   R-squared:                       0.000\n Model:                            OLS   Adj. R-squared:                  0.000\n Method:                 Least Squares   F-statistic:                     9.618\n Date:                Wed, 17 Apr 2024   Prob (F-statistic):            0.00193\n Time:                        22:48:20   Log-Likelihood:                 26630.\n No. Observations:               50083   AIC:                        -5.326e+04\n Df Residuals:                   50081   BIC:                        -5.324e+04\n Df Model:                           1                                         \n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n ------------------------------------------------------------------------------\n const          0.0179      0.001     16.225      0.000       0.016       0.020\n treatment      0.0042      0.001      3.101      0.002       0.002       0.007\n ==============================================================================\n Omnibus:                    59814.280   Durbin-Watson:                   2.005\n Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\n Skew:                           6.740   Prob(JB):                         0.00\n Kurtosis:                      46.440   Cond. No.                         3.23\n ==============================================================================\n \n Notes:\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n \"\"\")\n\n\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 17 Apr 2024   Pseudo R-squ.:               0.0009783\nTime:                        22:48:20   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\ndonations_ratio1 = data[data['ratio'] == 1]['gave']\ndonations_ratio2 = data[data['ratio'] == 2]['gave']\ndonations_ratio3 = data[data['ratio'] == 3]['gave']\n\nt_test_1_vs_2 = ttest_ind(donations_ratio1, donations_ratio2)\nt_test_1_vs_3 = ttest_ind(donations_ratio1, donations_ratio3)\nt_test_2_vs_3 = ttest_ind(donations_ratio2, donations_ratio3)\n\nt_test_1_vs_2, t_test_1_vs_3, t_test_2_vs_3\n\n(TtestResult(statistic=-0.96504713432247, pvalue=0.33453168549723933, df=22265.0),\n TtestResult(statistic=-1.0150255853798622, pvalue=0.31010466370866724, df=22260.0),\n TtestResult(statistic=-0.05011583793874515, pvalue=0.9600305283739325, df=22261.0))\n\n\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\n\nmodel_categorical = sm.OLS(y, X_categorical)\nresults_categorical = model_categorical.fit()\n\nprint(results_categorical.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.665\nDate:                Wed, 17 Apr 2024   Prob (F-statistic):             0.0118\nTime:                        22:48:21   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50079   BIC:                        -5.322e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0207      0.001     15.398      0.000       0.018       0.023\n2              0.0019      0.002      0.989      0.323      -0.002       0.006\n3              0.0020      0.002      1.041      0.298      -0.002       0.006\nControl       -0.0029      0.002     -1.661      0.097      -0.006       0.001\n==============================================================================\nOmnibus:                    59812.754   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4316693.217\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.438   Cond. No.                         5.09\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n# Define the ratios to be analyzed\nratios = ['1', '2', '3']\n\n# Calculate donation rates for each ratio\ndonation_rates = {ratio: data[data['ratio'] == ratio]['gave'].mean() for ratio in ratios}\n\n# Calculate differences between successive donation rates\nrate_differences = {f\"{ratios[i]}_to_{ratios[i+1]}\": donation_rates[ratios[i+1]] - donation_rates[ratios[i]]\n                    for i in range(len(ratios) - 1)}\n\n# Enhanced print statements with more detailed messaging\nfor diff_label, diff_value in rate_differences.items():\n    # Formatting the label for more readable output\n    ratio_pair = diff_label.replace('_', ' to ')\n    print(f\"Change in donation rates from {ratio_pair.replace(':', ' to ')} ratio: {diff_value:.6f}\")\n\nChange in donation rates from 1 to to to 2 ratio: 0.001884\nChange in donation rates from 2 to to to 3 ratio: 0.000100\n\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\n\n\nT-Statistic: 1.9182618934467577\nP-Value: 0.055085665289183336\n\n\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\n\n\nT-Statistic: -0.5846089794983359\nP-Value: 0.5590471865673547\n\n\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set the style of seaborn for more attractive and informative graphics\nsns.set(style=\"whitegrid\")\n\ndonors_data = data[data['amount'] &gt; 0]\n\ntreatment_donors = donors_data[donors_data['treatment'] == 1]['amount']\ncontrol_donors = donors_data[donors_data['treatment'] == 0]['amount']\n\ntreatment_mean = treatment_donors.mean()\ncontrol_mean = control_donors.mean()\n\nplt.figure(figsize=(14, 6))  # Adjusted for a better fit of both histograms\n\n# Histogram for the Treatment Group\nplt.subplot(1, 2, 1)\nsns.histplot(treatment_donors, bins=30, color='green', kde=True, edgecolor='black')\nplt.axvline(treatment_mean, color='darkred', linestyle='dashed', linewidth=2)\nplt.title('Treatment Group Donation Amounts')\nplt.xlabel('Donation Amount ($)')\nplt.ylabel('Frequency')\nplt.annotate(f'Mean: {treatment_mean:.2f}', xy=(treatment_mean, 10), xytext=(treatment_mean + 50, 12),\n             arrowprops=dict(facecolor='black', arrowstyle='-&gt;'))\n\n# Histogram for the Control Group\nplt.subplot(1, 2, 2)\nsns.histplot(control_donors, bins=30, color='purple', kde=True, edgecolor='black')\nplt.axvline(control_mean, color='darkred', linestyle='dashed', linewidth=2)\nplt.title('Control Group Donation Amounts')\nplt.xlabel('Donation Amount ($)')\nplt.ylabel('Frequency')\nplt.annotate(f'Mean: {control_mean:.2f}', xy=(control_mean, 10), xytext=(control_mean + 50, 12),\n             arrowprops=dict(facecolor='black', arrowstyle='-&gt;'))\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/Assignment1/hw1_questions.html#simulation-experiment",
    "href": "projects/Assignment1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters set by the professor\np_control = 0.018\np_treatment = 0.022\nn_simulations = 10000\n\n# Simulating outcomes\ncontrol_draws = np.random.binomial(1, p_control, n_simulations)\ntreatment_draws = np.random.binomial(1, p_treatment, n_simulations)\n\n# Calculating differences between treatment and control outcomes\ndiff_vector = treatment_draws - control_draws\n\n# Calculating cumulative average of differences over simulations\ncumulative_avg_diff = np.cumsum(diff_vector) / np.arange(1, n_simulations + 1)\n\n# Setting up the plot\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_avg_diff, color='blue', label='Cumulative Average of Differences')\nplt.axhline((p_treatment - p_control), color='red', linestyle='--', label='Expected Difference')\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average Difference')\nplt.title('Simulation of Difference Between Treatment and Control')\nplt.legend()\nplt.grid(True)  # Adding a grid for better readability of the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef simulate_and_plot_histograms(control_prob, treatment_prob, sample_sizes, num_repetitions=1000):\n    # Setting up the visual style using seaborn for more appealing histograms\n    sns.set(style=\"whitegrid\", palette=\"pastel\")\n\n    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n    fig.suptitle('Distribution of Difference in Proportions Across Sample Sizes')\n\n    for i, sample_size in enumerate(sample_sizes):\n        mean_differences = []\n\n        for _ in range(num_repetitions):\n            control_draws = np.random.binomial(1, control_prob, sample_size)\n            treatment_draws = np.random.binomial(1, treatment_prob, sample_size)\n            mean_differences.append(treatment_draws.mean() - control_draws.mean())\n\n        # Using seaborn for histogram plotting for improved aesthetics\n        sns.histplot(mean_differences, bins=30, kde=True, color='skyblue', ax=axes[i])\n        axes[i].axvline(0, color='red', linestyle='dashed', linewidth=2, label='No Difference')\n        axes[i].axvline(treatment_prob - control_prob, color='green', linestyle='dashed', linewidth=2, label='True Difference')\n        axes[i].set_title(f'Sample Size: {sample_size}')\n        axes[i].set_xlabel('Mean Difference')\n        axes[i].set_ylabel('Frequency')\n        if i == 0:  # Adding the legend to only the first subplot for clarity\n            axes[i].legend()\n\n    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n    plt.show()\n\n# Control and treatment probabilities given\ncontrol_prob = 0.018\ntreatment_prob = 0.022\n\n# List of sample sizes to simulate\nsample_sizes = [50, 200, 500, 1000]\n\n# Call the function with the updated parameters and visual setup\nsimulate_and_plot_histograms(control_prob, treatment_prob, sample_sizes)"
  }
]