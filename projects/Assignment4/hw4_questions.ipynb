{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Key Drivers Analysis\"\n",
        "author: \"Bansari Kathrotia\"\n",
        "date: today\n",
        "---"
      ],
      "id": "45ef68d7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This post implements a few measure of variable importance, interpreted as a key drivers analysis, for certain aspects of a payment card on customer satisfaction with that payment card.\n",
        "\n",
        "\n",
        "_todo: replicate the table on slide 19 of the session 4 slides. This involves calculating pearson correlations, standardized regression coefficients, \"usefulness\", Shapley values for a linear regression, Johnson's relative weights, and the mean decrease in the gini coefficient from a random forest. You may use packages built into R or Python._\n",
        "\n",
        "_If you want a challenge, either (1) implement one or more of the measures yourself. \"Usefulness\" is rather easy to program up. Shapley values for linear regression are a bit more work. Or (2) add additional measures to the table such as the importance scores from XGBoost._\n"
      ],
      "id": "a963b0ee"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data_path = 'data_for_drivers_analysis.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# Display the first few rows of the dataset to understand its structure\n",
        "data.head()"
      ],
      "id": "911e2c58",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate Pearson correlations\n",
        "correlations = data.corr()['satisfaction'].drop(['satisfaction', 'id', 'brand'])\n",
        "correlations"
      ],
      "id": "238c5d44",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Standardize the dataset\n",
        "features = ['trust', 'build', 'differs', 'easy', 'appealing', 'rewarding', 'popular', 'service', 'impact']\n",
        "X = data[features]\n",
        "y = data['satisfaction']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Perform multiple linear regression\n",
        "reg = LinearRegression()\n",
        "reg.fit(X_scaled, y)\n",
        "\n",
        "# Extract standardized coefficients\n",
        "standardized_coefficients = reg.coef_\n",
        "\n",
        "# Create a DataFrame to display the results\n",
        "standardized_coefficients_df = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Standardized Coefficient': standardized_coefficients\n",
        "}).sort_values(by='Standardized Coefficient', ascending=False)\n",
        "\n",
        "standardized_coefficients_df"
      ],
      "id": "3fe32374",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install necessary R packages using rpy2\n",
        "import rpy2.robjects.packages as rpackages\n",
        "from rpy2.robjects.vectors import StrVector\n",
        "\n",
        "# Check if the required R packages are installed and install if not\n",
        "utils = rpackages.importr('utils')\n",
        "utils.chooseCRANmirror(ind=1)\n",
        "\n",
        "# Install polycor package if not already installed\n",
        "packages_to_install = ['polycor']\n",
        "names_to_install = [x for x in packages_to_install if not rpackages.isinstalled(x)]\n",
        "if len(names_to_install) > 0:\n",
        "    utils.install_packages(StrVector(names_to_install))\n"
      ],
      "id": "686cd59e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import rpy2.robjects as robjects\n",
        "from rpy2.robjects import pandas2ri\n",
        "\n",
        "# Enable the automatic conversion between pandas and R data frames\n",
        "pandas2ri.activate()\n",
        "\n",
        "# Load the necessary R package\n",
        "polycor = rpackages.importr('polycor')\n",
        "\n",
        "# Convert the data to an R dataframe\n",
        "r_dataframe = pandas2ri.py2rpy(data)\n",
        "\n",
        "# Calculate Polychoric Correlations\n",
        "polychoric_correlations = {}\n",
        "for column in features:\n",
        "    polychoric_corr = polycor.hetcor(r_dataframe.rx2('satisfaction'), r_dataframe.rx2(column), ML=True)[0]\n",
        "    polychoric_correlations[column] = polychoric_corr[1, 0]\n",
        "\n",
        "# Convert the results to a pandas DataFrame\n",
        "polychoric_df = pd.DataFrame(list(polychoric_correlations.items()), columns=['Feature', 'Polychoric Correlation'])\n",
        "polychoric_df.sort_values(by='Polychoric Correlation', ascending=False, inplace=True)\n",
        "\n",
        "polychoric_df"
      ],
      "id": "a26e60b8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Standardize the dataset\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Perform multiple linear regression\n",
        "reg = LinearRegression()\n",
        "reg.fit(X_scaled, y)\n",
        "\n",
        "# Extract standardized coefficients\n",
        "standardized_coefficients = reg.coef_\n",
        "\n",
        "# Create a DataFrame to display the results\n",
        "standardized_coefficients_df = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Standardized Coefficient': standardized_coefficients\n",
        "}).sort_values(by='Standardized Coefficient', ascending=False)\n",
        "\n",
        "print(standardized_coefficients_df)"
      ],
      "id": "40f3898b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import shap\n",
        "\n",
        "# Fit the linear regression model again\n",
        "reg.fit(X, y)\n",
        "\n",
        "# Use SHAP to compute Shapley values\n",
        "explainer = shap.LinearExplainer(reg, X, feature_dependence=\"correlation\")\n",
        "shap_values = explainer.shap_values(X)\n",
        "\n",
        "# Summarize the mean absolute Shapley values for each feature\n",
        "shap_summary = np.mean(np.abs(shap_values), axis=0)\n",
        "shap_df = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Shapley Value': shap_summary\n",
        "}).sort_values(by='Shapley Value', ascending=False)\n",
        "\n",
        "print(shap_df)"
      ],
      "id": "2fe9522e",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}