---
title: "Key Drivers Analysis"
author: "Bansari Kathrotia"
date: today
---


This post implements a few measure of variable importance, interpreted as a key drivers analysis, for certain aspects of a payment card on customer satisfaction with that payment card.


_todo: replicate the table on slide 19 of the session 4 slides. This involves calculating pearson correlations, standardized regression coefficients, "usefulness", Shapley values for a linear regression, Johnson's relative weights, and the mean decrease in the gini coefficient from a random forest. You may use packages built into R or Python._

_If you want a challenge, either (1) implement one or more of the measures yourself. "Usefulness" is rather easy to program up. Shapley values for linear regression are a bit more work. Or (2) add additional measures to the table such as the importance scores from XGBoost._


```{python}
#| echo: false
#| message: false

import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score
from itertools import combinations
from sklearn.metrics import mean_squared_error
import numpy as np
from sklearn.ensemble import RandomForestRegressor

```

```{python}

#| echo: true
#| message: true

# Load the dataset
data_path = 'data_for_drivers_analysis.csv'
data = pd.read_csv(data_path)

# Display the first few rows of the dataset to understand its structure
data.head()
```


```{python}

#| echo: true
#| message: true

# Calculate Pearson correlation coefficients
pearson_corr = data.corr()['satisfaction'].drop('satisfaction').apply(lambda x: x * 100).round(1)
print("Pearson Correlations:\n", pearson_corr)
```

```{python}
#| echo: false
#| message: true

# Prepare the data for regression
X = data.drop(columns=['brand', 'id', 'satisfaction'])
y = data['satisfaction']

# Standardize the features
scaler = StandardScaler()
X_std = scaler.fit_transform(X)
```


```{python}

#| echo: true
#| message: true

# Fit the linear regression model
reg = LinearRegression().fit(X_std, y)
coefficients = reg.coef_
```



```{python}

#| echo: true
#| message: true

# Standardized coefficients
std_coeff = pd.Series(coefficients, index=X.columns).apply(lambda x: x * 100).round(1)
print("Standardized Regression Coefficients:\n", std_coeff)

```



```{python}
#| echo: false
#| message: true

# Calculate the baseline R^2
baseline_r2 = r2_score(y, reg.predict(X_std))

usefulness = {}
for feature in X.columns:
    X_dropped = X.drop(columns=[feature])
    X_dropped_std = scaler.fit_transform(X_dropped)
    reg_dropped = LinearRegression().fit(X_dropped_std, y)
    dropped_r2 = r2_score(y, reg_dropped.predict(X_dropped_std))
    usefulness[feature] = (baseline_r2 - dropped_r2) * 100

```



```{python}
#| echo: true
#| message: true

usefulness_series = pd.Series(usefulness).round(1)
print("Usefulness:\n", usefulness_series)

```



```{python}

#| echo: false
#| message: true


def compute_shapley_values(X, y):
    features = X.columns
    base_model = LinearRegression().fit(X, y)
    base_prediction = base_model.predict(X)
    base_mse = mean_squared_error(y, base_prediction)
    
    shapley_values = pd.Series(0.0, index=features)
    
    for feature in features:
        without_feature = X.drop(columns=[feature])
        without_model = LinearRegression().fit(without_feature, y)
        without_prediction = without_model.predict(without_feature)
        without_mse = mean_squared_error(y, without_prediction)
        
        shapley_values[feature] = abs(base_mse - without_mse)  # Absolute value to reflect positive contribution
    
    shapley_values = shapley_values.apply(lambda x: x * 100).round(1)
    return shapley_values

```

```{python}

#| echo: true
#| message: true

shapley_values = compute_shapley_values(X, y)
print("Shapley Values:\n", shapley_values)
```


```{python}

#| echo: false
#| message: true

# Compute the correlation matrix
correlation_matrix = np.corrcoef(X_std, rowvar=False)

# Compute the eigenvalues and eigenvectors
eigenvalues, eigenvectors = np.linalg.eig(correlation_matrix)

```

```{python}

#| echo: true
#| message: true

# Compute the relative weights
relative_weights = (eigenvectors ** 2).dot(eigenvalues) / np.sum(eigenvalues)
johnsons_epsilon = pd.Series(relative_weights, index=X.columns).apply(lambda x: x * 100).round(1)

print("Johnson's Relative Weights (Epsilon):\n", johnsons_epsilon)
```


```{python}
#| echo: false
#| message: true

# Train the Random Forest model
rf = RandomForestRegressor()
rf.fit(X, y)

```

```{python}
#| echo: true
#| message: true

# Compute the mean decrease in Gini coefficient
gini_importance = pd.Series(rf.feature_importances_, index=X.columns).apply(lambda x: x * 100).round(1)

print("Mean Decrease in Gini Coefficient:\n", gini_importance)
```


```{python}

#| echo: false
#| message: true

# Remove 'brand' and 'id' from the results
pearson_corr_cleaned = pearson_corr.drop(index=['brand', 'id'], errors='ignore')
usefulness_series_cleaned = usefulness_series.drop(index=['brand', 'id'], errors='ignore')
shapley_values_cleaned = shapley_values.drop(index=['brand', 'id'], errors='ignore')
johnsons_epsilon_cleaned = johnsons_epsilon.drop(index=['brand', 'id'], errors='ignore')
gini_importance_cleaned = gini_importance.drop(index=['brand', 'id'], errors='ignore')

# Combine results into a single DataFrame
results_cleaned = pd.DataFrame({
    'Pearson Correlations': pearson_corr_cleaned,
    'Standardized Regression Coefficients': std_coeff,
    'Usefulness': usefulness_series_cleaned,
    'Shapley Values': shapley_values_cleaned,
    'Johnson\'s Epsilon': johnsons_epsilon_cleaned,
    'Mean Decrease in Gini Coefficient': gini_importance_cleaned
})

# Apply styling
styled_results_cleaned = results_cleaned.style.format("{:.1f}%").background_gradient(cmap='coolwarm', axis=0)

```

```{python}
#| echo: true
#| message: true

# Display the styled DataFrame
styled_results_cleaned
```

```{python}

#| echo: false
#| message: false

# Save styled table as HTML
# styled_results_cleaned.to_html("styled_results_cleaned.html")

# print("Styled table saved as 'styled_results_cleaned.html'. Open this file in a web browser to view the table.")
```